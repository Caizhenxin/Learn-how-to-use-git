{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3D0E752CE0A446EBC38944CEB64D6D3",
    "jupyter": {},
    "notebookId": "655b69f19f41eb29b96aa410",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# <center> Lecture11 : Evaluating Regression Models </center>  \n",
    " \n",
    "## <center> Instructor: Dr. Hu Chuan-Peng </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问题回顾\n",
    "\n",
    "还记得我们上节课的思考题吗？\n",
    "\n",
    "🤔贝叶斯回归模型与传统的线性回归模型得到的结论是否一致？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，让我们回顾上节课定义的三种线性模型，并且通过 PyMC 进行定义和拟合。\n",
    "\n",
    "|模型|参数|解释|  \n",
    "|-|-|-|  \n",
    "|model 1|RT ~ Label|简单线性回归模型：自变量为两水平的离散变量|   \n",
    "|model 2|RT ~ Label + Matching|多元回归模型：自变量为两水平的离散变量和多水平的离散变量|  \n",
    "|model 3|RT ~ Label + Matching + Label:Matching|多元回归模型：自变量额外增加了两个自变量间的交互作用|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "# 导入 pymc 模型包，和 arviz 等分析工具 \n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 忽略不必要的警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  df_raw = pd.read_csv('/home/mw/input/bayes3797/Kolvoort_2020_HBM_Exp1_Clean.csv')\n",
    "except:\n",
    "  df_raw = pd.read_csv('/data/Kolvoort_2020_HBM_Exp1_Clean.csv')\n",
    "\n",
    "df = df_raw.groupby(['Subject','Label', 'Matching'], as_index=False)['RT_sec'].mean()\n",
    "\n",
    "# 将 Label 列的数字编码转为文字标签\n",
    "df['Label'] = df['Label'].replace({1: 'Self', 2: 'Friend', 3: 'Stranger'})\n",
    "\n",
    "df['Matching'] = df['Matching'].replace({'Matching': 'matching', 'Nonmatching': 'nonmatching'})\n",
    "\n",
    "# 设置索引\n",
    "df[\"index\"] = range(len(df))\n",
    "df = df.set_index(\"index\")\n",
    "\n",
    "# 将 Label 列转换为有序的分类变量\n",
    "df['Label'] = pd.Categorical(df['Label'], categories=['Self', 'Friend', 'Stranger'], ordered=True)\n",
    "\n",
    "# 将分类变量转换为哑变量\n",
    "X1 = (df['Label'] == 'Friend').astype(int)\n",
    "X2 = (df['Label'] == 'Stranger').astype(int)\n",
    "\n",
    "# Matching 条件的哑变量\n",
    "Matching = (df['Matching'] == 'matching').astype(int)  \n",
    "\n",
    "# Friend 和 Matching 的交互\n",
    "Interaction_1 = X1 * Matching  \n",
    "\n",
    "# Stranger 和 Matching 的交互\n",
    "Interaction_2 = X2 * Matching  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 建立模型1\n",
    "with pm.Model() as model1:\n",
    "    # 定义先验分布参数\n",
    "    beta_0 = pm.Normal('beta_0', mu=5, sigma=2)\n",
    "    beta_1 = pm.Normal('beta_1', mu=0, sigma=1)\n",
    "    beta_2 = pm.Normal('beta_2', mu=0, sigma=1)\n",
    "    sigma = pm.Exponential('sigma', lam=0.3)\n",
    "    \n",
    "    # 线性模型表达式\n",
    "    mu = beta_0 + beta_1 * X1 + beta_2 * X2\n",
    "    \n",
    "    # 观测数据的似然函数\n",
    "    likelihood = pm.Normal('Y_obs', mu=mu, sigma=sigma, observed=df['RT_sec'])\n",
    "\n",
    "# 建立模型2和模型3\n",
    "\n",
    "with pm.Model() as model2:\n",
    "    # 先验分布\n",
    "    beta_0 = pm.Normal('beta_0', mu=5, sigma=2)  \n",
    "    beta_1 = pm.Normal('beta_1', mu=0, sigma=1)  \n",
    "    beta_2 = pm.Normal('beta_2', mu=0, sigma=1)  \n",
    "    beta_3 = pm.Normal('beta_3', mu=0, sigma=1)  \n",
    "    sigma = pm.Exponential('sigma', lam=0.3)  \n",
    "    \n",
    "    # 线性模型\n",
    "    mu = beta_0 + beta_1 * X1 + beta_2 * X2 + beta_3 * Matching\n",
    "    \n",
    "    # 观测数据的似然函数\n",
    "    likelihood = pm.Normal('Y_obs', mu=mu, sigma=sigma, observed=df['RT_sec'])\n",
    "\n",
    "with pm.Model() as model3:\n",
    "    # 定义先验分布\n",
    "    beta_0 = pm.Normal('beta_0', mu=5, sigma=2)  \n",
    "    beta_1 = pm.Normal('beta_1', mu=0, sigma=1) \n",
    "    beta_2 = pm.Normal('beta_2', mu=0, sigma=1)  \n",
    "    beta_3 = pm.Normal('beta_3', mu=0, sigma=1)  \n",
    "    beta_4 = pm.Normal('beta_4', mu=0, sigma=1) \n",
    "    beta_5 = pm.Normal('beta_5', mu=0, sigma=1)  \n",
    "    sigma = pm.Exponential('sigma', lam=0.3)  \n",
    "    \n",
    "    # 线性模型\n",
    "    mu = (beta_0 + beta_1 * X1 + beta_2 * X2 + beta_3 * Matching +\n",
    "          beta_4 * Interaction_1 + beta_5 * Interaction_2)\n",
    "    \n",
    "    # 观测数据的似然函数\n",
    "    likelihood = pm.Normal('Y_obs', mu=mu, sigma=sigma, observed=df['RT_sec'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载现有的采样结果：lec10_model1.nc\n",
      "加载现有的采样结果：lec10_model2.nc\n",
      "加载现有的采样结果：lec10_model3.nc\n"
     ]
    }
   ],
   "source": [
    "#===========================\n",
    "#     注意！！！以下代码可能需要运行3分钟左右\n",
    "#===========================\n",
    "\n",
    "def run_model_sampling(save_name, model=None, draws=5000, tune=1000, chains=4, random_seed=84735):\n",
    "    \"\"\"\n",
    "    运行模型采样，并在结果不存在时进行采样，存在时直接加载结果。\n",
    "\n",
    "    Parameters:\n",
    "    - save_name: 用于保存或加载结果的文件名（无扩展名）\n",
    "    - model: pymc 模型\n",
    "    - draws: 采样次数 (默认5000)\n",
    "    - tune: 调整采样策略的次数 (默认1000)\n",
    "    - chains: 链数 (默认4)\n",
    "    - random_seed: 随机种子 (默认84735)\n",
    "\n",
    "    Returns:\n",
    "    - trace: 采样结果\n",
    "    \"\"\"\n",
    "    \n",
    "    # 检查是否存在保存的.nc文件\n",
    "    nc_file = f\"{save_name}.nc\"\n",
    "    if os.path.exists(nc_file):\n",
    "        print(f\"加载现有的采样结果：{nc_file}\")\n",
    "        # 如果文件存在，则加载采样结果\n",
    "        trace = az.from_netcdf(nc_file)\n",
    "    else:\n",
    "\n",
    "        assert model is not None, \"模型未定义，请先定义模型\"\n",
    "\n",
    "        print(f\"没有找到现有的采样结果，正在执行采样：{save_name}\")\n",
    "        # 如果文件不存在，则进行采样计算\n",
    "        with model:\n",
    "            trace = pm.sample_prior_predictive(draws=draws, random_seed=random_seed)\n",
    "            idata = pm.sample(draws=draws,                   # 使用mcmc方法进行采样，draws为采样次数\n",
    "                              tune=tune,                    # tune为调整采样策略的次数\n",
    "                              chains=chains,                # 链数\n",
    "                              discard_tuned_samples=True,   # tune的结果将在采样结束后被丢弃\n",
    "                              idata_kwargs={\"log_likelihood\": True},\n",
    "                              random_seed=random_seed)      # 后验采样\n",
    "\n",
    "            trace.extend(idata)\n",
    "            # 进行后验预测并扩展推断数据\n",
    "            pm.sample_posterior_predictive(trace, extend_inferencedata=True, random_seed=random_seed)\n",
    "            \n",
    "            # 保存结果到指定文件\n",
    "        trace.to_netcdf(nc_file)\n",
    "        \n",
    "    return trace\n",
    "\n",
    "# 运行所有三个模型\n",
    "model1_trace = run_model_sampling(\"lec10_model1\",model1)\n",
    "model2_trace = run_model_sampling(\"lec10_model2\",model2)\n",
    "model3_trace = run_model_sampling(\"lec10_model3\",model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 与传统线性回归做法的对比：\n",
    "\n",
    "为检测模型是否合理，我们可以将贝叶斯模型与传统的线性回归模型进行对比。\n",
    "\n",
    "我们将以 model3 为例，使用statsmodels库来构建一个传统的线性回归模型，并将其结果与贝叶斯模型的结果进行比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>RT_sec</td>      <th>  R-squared:         </th> <td>   0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 27 Nov 2024</td> <th>  Prob (F-statistic):</th>  <td>0.0418</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:04:32</td>     <th>  Log-Likelihood:    </th> <td>  115.01</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   186</td>      <th>  AIC:               </th> <td>  -218.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   180</td>      <th>  BIC:               </th> <td>  -198.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>    0.7277</td> <td>    0.024</td> <td>   30.570</td> <td> 0.000</td> <td>    0.681</td> <td>    0.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>            <td>    0.0488</td> <td>    0.034</td> <td>    1.449</td> <td> 0.149</td> <td>   -0.018</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>            <td>    0.0326</td> <td>    0.034</td> <td>    0.970</td> <td> 0.333</td> <td>   -0.034</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Matching</th>      <td>   -0.0501</td> <td>    0.034</td> <td>   -1.487</td> <td> 0.139</td> <td>   -0.116</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Interaction_1</th> <td>    0.0305</td> <td>    0.048</td> <td>    0.640</td> <td> 0.523</td> <td>   -0.063</td> <td>    0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Interaction_2</th> <td>    0.0568</td> <td>    0.048</td> <td>    1.194</td> <td> 0.234</td> <td>   -0.037</td> <td>    0.151</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 7.639</td> <th>  Durbin-Watson:     </th> <td>   0.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.022</td> <th>  Jarque-Bera (JB):  </th> <td>   7.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.477</td> <th>  Prob(JB):          </th> <td>  0.0241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.227</td> <th>  Cond. No.          </th> <td>    9.77</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &     RT\\_sec      & \\textbf{  R-squared:         } &     0.062   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.036   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     2.362   \\\\\n",
       "\\textbf{Date:}             & Wed, 27 Nov 2024 & \\textbf{  Prob (F-statistic):} &   0.0418    \\\\\n",
       "\\textbf{Time:}             &     11:04:32     & \\textbf{  Log-Likelihood:    } &    115.01   \\\\\n",
       "\\textbf{No. Observations:} &         186      & \\textbf{  AIC:               } &    -218.0   \\\\\n",
       "\\textbf{Df Residuals:}     &         180      & \\textbf{  BIC:               } &    -198.7   \\\\\n",
       "\\textbf{Df Model:}         &           5      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                        & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}          &       0.7277  &        0.024     &    30.570  &         0.000        &        0.681    &        0.775     \\\\\n",
       "\\textbf{X1}             &       0.0488  &        0.034     &     1.449  &         0.149        &       -0.018    &        0.115     \\\\\n",
       "\\textbf{X2}             &       0.0326  &        0.034     &     0.970  &         0.333        &       -0.034    &        0.099     \\\\\n",
       "\\textbf{Matching}       &      -0.0501  &        0.034     &    -1.487  &         0.139        &       -0.116    &        0.016     \\\\\n",
       "\\textbf{Interaction\\_1} &       0.0305  &        0.048     &     0.640  &         0.523        &       -0.063    &        0.124     \\\\\n",
       "\\textbf{Interaction\\_2} &       0.0568  &        0.048     &     1.194  &         0.234        &       -0.037    &        0.151     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  7.639 & \\textbf{  Durbin-Watson:     } &    0.534  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.022 & \\textbf{  Jarque-Bera (JB):  } &    7.449  \\\\\n",
       "\\textbf{Skew:}          & -0.477 & \\textbf{  Prob(JB):          } &   0.0241  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.227 & \\textbf{  Cond. No.          } &     9.77  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 RT_sec   R-squared:                       0.062\n",
       "Model:                            OLS   Adj. R-squared:                  0.036\n",
       "Method:                 Least Squares   F-statistic:                     2.362\n",
       "Date:                Wed, 27 Nov 2024   Prob (F-statistic):             0.0418\n",
       "Time:                        11:04:32   Log-Likelihood:                 115.01\n",
       "No. Observations:                 186   AIC:                            -218.0\n",
       "Df Residuals:                     180   BIC:                            -198.7\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const             0.7277      0.024     30.570      0.000       0.681       0.775\n",
       "X1                0.0488      0.034      1.449      0.149      -0.018       0.115\n",
       "X2                0.0326      0.034      0.970      0.333      -0.034       0.099\n",
       "Matching         -0.0501      0.034     -1.487      0.139      -0.116       0.016\n",
       "Interaction_1     0.0305      0.048      0.640      0.523      -0.063       0.124\n",
       "Interaction_2     0.0568      0.048      1.194      0.234      -0.037       0.151\n",
       "==============================================================================\n",
       "Omnibus:                        7.639   Durbin-Watson:                   0.534\n",
       "Prob(Omnibus):                  0.022   Jarque-Bera (JB):                7.449\n",
       "Skew:                          -0.477   Prob(JB):                       0.0241\n",
       "Kurtosis:                       3.227   Cond. No.                         9.77\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# 构建设计矩阵\n",
    "X = sm.add_constant(\n",
    "    pd.DataFrame({\n",
    "        'X1': X1, \n",
    "        'X2': X2, \n",
    "        'Matching': Matching,\n",
    "        'Interaction_1': Interaction_1,\n",
    "        'Interaction_2': Interaction_2\n",
    "    })\n",
    ")\n",
    "y = df['RT_sec']\n",
    "\n",
    "# 传统线性回归模型\n",
    "model0 = sm.OLS(y, X).fit()\n",
    "\n",
    "# 打印回归结果\n",
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_2.5%</th>\n",
       "      <th>hdi_97.5%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta_0</th>\n",
       "      <td>0.729</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8434.0</td>\n",
       "      <td>10823.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_1</th>\n",
       "      <td>0.047</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9077.0</td>\n",
       "      <td>11295.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_2</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9429.0</td>\n",
       "      <td>11853.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_3</th>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8437.0</td>\n",
       "      <td>11481.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_4</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9113.0</td>\n",
       "      <td>11619.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_5</th>\n",
       "      <td>0.058</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9541.0</td>\n",
       "      <td>12573.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>0.133</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13797.0</td>\n",
       "      <td>13194.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean     sd  hdi_2.5%  hdi_97.5%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "beta_0  0.729  0.024     0.682      0.775        0.0      0.0    8434.0   \n",
       "beta_1  0.047  0.034    -0.021      0.112        0.0      0.0    9077.0   \n",
       "beta_2  0.032  0.034    -0.034      0.097        0.0      0.0    9429.0   \n",
       "beta_3 -0.051  0.033    -0.117      0.012        0.0      0.0    8437.0   \n",
       "beta_4  0.032  0.047    -0.061      0.122        0.0      0.0    9113.0   \n",
       "beta_5  0.058  0.047    -0.034      0.150        0.0      0.0    9541.0   \n",
       "sigma   0.133  0.007     0.120      0.147        0.0      0.0   13797.0   \n",
       "\n",
       "        ess_tail  r_hat  \n",
       "beta_0   10823.0    1.0  \n",
       "beta_1   11295.0    1.0  \n",
       "beta_2   11853.0    1.0  \n",
       "beta_3   11481.0    1.0  \n",
       "beta_4   11619.0    1.0  \n",
       "beta_5   12573.0    1.0  \n",
       "sigma    13194.0    1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 注意，可以通过 az.plot_bf() 函数来计算贝叶斯因子（Bayes Factor）。\n",
    "az.summary(model3_trace, hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**我们可以对比两个模型的结果**\n",
    "\n",
    "- 贝叶斯回归提供了更多关于参数不确定性的细节，\n",
    "- 而传统的 OLS 回归提供了点估计、标准误差、置信区间和 p 值，适合用于传统的显著性检验和模型评估。\n",
    "\n",
    "\n",
    "| 参数               | 贝叶斯回归（Bayesian Regression）                                   | 传统线性回归（OLS Regression）  |\n",
    "|------------------|---------------------------------------------------|---------------------------------|\n",
    "| **$\\beta_0$**        | Mean: 0.729<br>SD: 0.024<br>HDI: [0.682, 0.775]<br>BF10: 0.2        | Mean: 0.7277<br>SE: 0.024<br>95% CI: [0.681, 0.775]<br>$p = 0.000$ |\n",
    "| **$\\beta_1$**        | Mean: 0.047<br>SD: 0.034<br>HDI: [-0.021, 0.112]<br>BF10: 0.09      | Mean: 0.0488<br>SE: 0.034<br>95% CI: [-0.018, 0.115]<br>$p = 0.149$ |\n",
    "| **$\\beta_2$**        | Mean: 0.032<br>SD: 0.034<br>HDI: [-0.034, 0.097]<br>BF10: 0.05      | Mean: 0.0326<br>SE: 0.034<br>95% CI: [-0.034, 0.099]<br>$p = 0.333$ |\n",
    "| **$\\beta_3$**        | Mean: -0.051<br>SD: 0.033<br>HDI: [-0.117, 0.012]<br>BF10: 0.1      | Mean: -0.0501<br>SE: 0.034<br>95% CI: [-0.116, 0.016]<br>$p = 0.139$ |\n",
    "| **$\\beta_4$**        | Mean: 0.032<br>SD: 0.047<br>HDI: [-0.061, 0.122]<br>BF10: 0.06      | Mean: 0.0305<br>SE: 0.048<br>95% CI: [-0.063, 0.124]<br>$p = 0.523$ |\n",
    "| **$\\beta_5$**        | Mean: 0.058<br>SD: 0.047<br>HDI: [-0.034, 0.150]<br>BF10: 0.1       | Mean: 0.0568<br>SE: 0.048<br>95% CI: [-0.037, 0.151]<br>$p = 0.234$ |\n",
    "| **$\\sigma$**         | Mean: 0.133<br>SD: 0.007<br>HDI: [0.120, 0.147]                    | -                               |\n",
    "| **模型R²**           | -                                                                 | R-squared: 0.062 |\n",
    "| **模型调整R²**       | -                                                                 | Adjusted R-squared: 0.036 |\n",
    "| **F-statistic**      | -                                                                 | F-statistic: 2.362<br>$p = 0.0418$ |\n",
    "| **Log-Likelihood**   | -                                                                 | Log-Likelihood: 115.01 |\n",
    "| **AIC**              | -                                                                 | AIC: -218.0 |\n",
    "| **BIC**              | -                                                                 | BIC: -198.7 |\n",
    "\n",
    "\n",
    "<div style=\"padding-bottom: 30px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评估与比较 (Model Evaluation & Comparison)  \n",
    "\n",
    "在模型评估中，**贝叶斯回归**和**传统线性回归**模型在参数估计上的结果非常接近。但是，它们的区别在于对参数的不确定性评估。\n",
    "* 贝叶斯模型提供了明确的参数分布，包括 **均值**、**标准差** 和 **高密度区间**（HDI），这使得我们可以更清晰地了解参数估计的不确定性。\n",
    "* 而传统线性回归则侧重于给出参数的点估计，并通过 **标准误差** 和 **95% 置信区间** 进行评估。虽然传统模型没有明确给出不确定性，但它通过 ***p 值***、**R²** 等统计量提供了其他重要信息。\n",
    "\n",
    "\n",
    "**🤔思考**\n",
    "\n",
    "**传统回归分析**提供了更多的 **模型评估指标📊**，如 **R²**、**调整后的 R²**、**F 统计量**、**对数似然**、**AIC** 和 **BIC** 等。这些指标不仅帮助我们评估模型的拟合优度，还能有效地比较不同模型的复杂性和预测效果。\n",
    "\n",
    "在第十课中，我们已经探索了多个研究假设和模型。那么，**哪一个模型对于数据的预测效果最好**呢？我们又该如何通过这些评估指标来做出更有力的比较呢？\n",
    "\n",
    "**📈💡接下来的步骤：**\n",
    "我们将深入讨论如何使用具体的 **评估指标** 来量化模型性能，并根据这些指标对模型进行**评估**和**比较**。\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/rkz1dqyo2e.png?imageView2/0/w/700)\n",
    "\n",
    "<div style=\"padding-bottom: 30px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 什么是模型评估？\n",
    "\n",
    "\n",
    "模型评估则是指对模型是否公平性、有效性、可信性进行评估，既可以是对单个模型，也可以是对多个模型进行。 \n",
    "\n",
    "模型评估与比较(Model evaluation & comparison)的目的在于选择最好的模型。  \n",
    "\n",
    "什么需要模型比较？  \n",
    "\n",
    "1. 例如，比较 mode3 和 model2 可以帮助我们确定“Label”和“Matching”之间的交互或调节作用。  \n",
    "2. 例如，比较 model2 和 model1 可以衡量增加预测因子是否能提升模型的预测能力。  \n",
    "- 总之，模型比较的目的随着研究目的变化而变化。  \n",
    "\n",
    "|模型|参数|解释|  \n",
    "|-|-|-|  \n",
    "|model 1|RT ~ Label|简单线性回归模型：自变量为两水平的离散变量|   \n",
    "|model 2|RT ~ Label + Matching|多元回归模型：自变量为两水平的离散变量和多水平的离散变量|  \n",
    "|model 3|RT ~ Label + Matching + Label:Matching|多元回归模型：自变量额外增加了两个自变量间的交互作用|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* 我们可以从以下三个角度来思考这个问题：  \n",
    "\n",
    "1. 模型本身公正吗？(How fair is the model?)  \n",
    "    - 公平性(How fair)：模型在数据收集和分析的整个流程中的公正性。  \n",
    "\n",
    "2. 模型存在错误吗？(How wrong is the model?)  \n",
    "   - 错误程度(How wrong)：模型在**实践**中是否有效？即是否能够准确地预测**样本**数据。\n",
    "  \n",
    "3.  后验预测模型有多准确？(How accurate are the posterior predictive models?) \n",
    "    - 准确性(How accurate)：模型是否反映**现实规律**？即是否能够准确地预测**样本外**数据。  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型公正吗(Is the model fair?)  \n",
    "\n",
    "模型公正性是一个上位概念，它描述了模型是否符合我们(社会、道德、伦理)的预期，而不仅是关注模型和样本数据的关系。  \n",
    "\n",
    "我们可以借助几个相关问题来理解和思考模型的公众性：  \n",
    "\n",
    "1. 数据的收集过程是怎样的？  \n",
    "\n",
    "   - 数据的收集过程直接影响模型的公正性。如果数据收集的过程存在偏见或不充分考虑多样性，那么模型就可能会产生不公正的结果。\n",
    "\n",
    "   - 例如，某些群体的数据可能被忽视或代表性不足，导致模型结果不具备广泛的适用性或公平性。\n",
    "\n",
    "2. 数据由谁收集，数据收集的目的是什么？  \n",
    "   \n",
    "   - 数据收集者的身份、意图和研究目的，都会影响数据的性质和使用方式。\n",
    "  \n",
    "   - 资本主义的核心观念推动了个体主义和竞争性思维，可能导致研究样本的偏倚，削弱了全球不同文化和社会背景的代表性。\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 数据的收集的过程公平吗？**  \n",
    "\n",
    "在本示例研究中，数据来源于基于自我匹配范式的实验数据，这些数据通过线下认知实验收集而得。\n",
    "\n",
    "* 数据收集过程是公平的，被试填写了实验的知情同意书，并获得相应的报酬。  \n",
    "* 此外，数据收集过程是匿名化的，保护了被试的隐私。  \n",
    "\n",
    "潜在偏见，如：  \n",
    "* 在数据收集过程中，仅选取大学生群体作为样本，而忽略其他重要的人群。\n",
    "\n",
    "🤔基于这些数据的模型公正吗？  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**心理学研究背后的内隐哲学观**\n",
    "\n",
    "在研究过程中未被明确提及，却深刻影响研究设计和解释的潜在观念和假设形成了心理学研究背后的内隐哲学观。\n",
    "\n",
    "主要包括普遍性假设导致的对文化差异考量不足，以及资本主义核心观念导致的研究样本偏倚。这些内隐观念可能使研究忽视文化多样性和社会不平等，从而影响研究的全面性、准确性和应用价值。\n",
    "\n",
    "|内隐哲学观方面|重要性|作用|影响|新的提倡|\n",
    "|----|----|----|----|----|\n",
    "|普遍性假设与文化差异考量不足|构建准确全面且具文化适应性理论|使研究忽略文化因素，影响各环节|限制理论普适性，阻碍心理学全球发展|数据收集多样化、文化敏感性培训、理论构建多元视角|\n",
    "|资本主义核心观念与研究样本偏倚|确保研究样本多样性和代表性|导致样本选择偏向西方或资本主义文化个体|研究结果有偏差，不利于跨文化研究|扩大样本来源、提高研究者文化敏感性、融合多元文化理论|\n",
    "\n",
    "> 参考文献：Bettache, K. (2024). Where Is Capitalism? Unmasking Its Hidden Role in Psychology. *Personality and Social Psychology Review*, *0*(0). https://doi.org/10.1177/10888683241287570\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 研究目的，以及数据收集的目的公平吗？**  \n",
    "\n",
    "在本示例研究中，研究目的来源自心理学家的好奇和假设。这是合理的，因为心理学研究是一种探索性的研究方法。  \n",
    "\n",
    "一些极端的反例：  \n",
    "* 如果研究项目来源于开发缓解压力药的厂商。那么，研究目的就可能被操纵，以支持药厂的销售。  \n",
    "* 例如，有目的的选择被试。  \n",
    "* 例如，有目的性的将实验目告诉被试，从而收集到符合预期的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据由谁收集，数据收集的目的是什么？** \n",
    "   \n",
    "数据收集者的身份、意图和研究目的，都会影响数据的性质和使用方式。\n",
    "  \n",
    "研究者可能内隐地假设心理学现象具有普遍性，但未充分考虑文化差异，这种内隐假设影响了结果的解释，忽视了不同社会和文化背景对心理现象的深刻影响(Ghai, Forscher, & Chuan-Peng, 2024)。\n",
    "\n",
    "从这张图中，你可以发现什么？🤔\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/sno3jb9h3b.png?imageView2/0/w/720/h/960)\n",
    "\n",
    "> 参考文献：Ghai, S., Forscher, P.S. & Chuan-Peng, H. Big-team science does not guarantee generalizability. *Nat Hum Behav* **8**, 1053–1056 (2024). https://doi.org/10.1038/s41562-024-01902-y\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"padding-bottom: 30px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 模型分析的结果，将对个人和社会产生什么影响？**  \n",
    "\n",
    "在本示例研究中，研究结果(模型分析的结果)具有一定的理论意义和实际意义。  \n",
    "* 在理论层面， 自我匹配范式中的模型能够帮助揭示个体如何处理与“自我”相关的信息。\n",
    "* 在实际意义层面，通过这些模型，可以更精确地识别个体在自我认知过程中的偏差。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. 分析过程中包含的偏见？**  \n",
    "\n",
    "一些反例：  \n",
    "* 假设在一次研究中使用多种问卷收集多种因变量，然后选择有相关性的变量进行报告?  \n",
    "* 在多因素实验设计中，通过增加变量来获得显著的交互作用，并尝试多种简单效应分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在心理学研究中，模型公正性往往与***心理学研究的可重复性***相关。  \n",
    "\n",
    "1. 数据的收集过程是怎样的？  \n",
    "\n",
    "2. 数据由谁收集，数据收集的目的是什么？  \n",
    "\n",
    "3. 数据收集的过程，以及分析的结果，将对个人和社会产生什么影响？  \n",
    "\n",
    "4. 分析过程中可能会包含哪些偏见  \n",
    "    * *p*-hacking/HARKing  \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://pic2.zhimg.com/80/v2-778de6c621356bc2c23c3a09ff2b0be5_1440w.webp\" \n",
    "         alt=\"Image Description\" \n",
    "         style=\"width: 60%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "(来源：胡传鹏, ..., 彭凯平. (2016). 心理学研究中的可重复性问题:从危机到契机. *心理科学进展, 24*(9), 1504-1518. doi: 10.3724/SP.J.1042.2016.01504)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这个模型可能有多错误(How wrong is the model?)  \n",
    "\n",
    "\n",
    ">  **<center>“all models are wrong, but some are useful.   ————George Box”</center>**  \n",
    "\n",
    "\n",
    "* 尽管统计模型是对更复杂现实的简化表达，良好的统计模型仍然可以是有用的，并可以增进我们对世界复杂性的理解。  \n",
    "\n",
    "* 因此，在评估模型时，要问的下一个问题不是模型是否错误(is the model wrong?)，而是模型错误的程度(How wrong is the model?)  \n",
    "\n",
    "🤔思考贝叶斯线性回归模型的假设在多大程度上与现实相符？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型假设的影响  \n",
    "\n",
    "**🤔 我们知道模型存在前提预设(assumption)，如果这些模型的前提预设不成立，模型会变得多糟糕？**  \n",
    "\n",
    "在lec9中，我们使用一个线性模型来定义标签“Label”与反应时间“RT”之间的关系，并且指定了该模型成立的一些前提预设。  \n",
    "\n",
    "$$  \n",
    "\\begin{align*}  \n",
    "Y_i &= \\beta_0 + \\beta_1 X_i + \\epsilon \\;\\;\\;\\;\\;\\;\\;\\;\\epsilon \\sim N(0,\\sigma^2)\\\\  \n",
    "&\\Downarrow \\\\  \n",
    "Y_i | \\beta_0, \\beta_1, \\sigma &\\stackrel{ind}{\\sim} N\\left(\\mu_i, \\sigma^2\\right) \\;\\; \\text{ with } \\;\\; \\mu_i = \\beta_0 + \\beta_1X_i  .\\\\  \n",
    "\\end{align*}  \n",
    "$$  \n",
    "\n",
    "* 回归模型需满足如下假设：  \n",
    "\n",
    "    1. 独立观测假设: 每个观测值$Y_i$是相互独立的，即一个观测的值不受其他观测的影响.  \n",
    "\n",
    "    2. 线性关系假设: 预测值$\\mu_i$和自变量$X_i$之间可以用线性关系来描述，即：$\\mu_i = \\beta_0 + \\beta_1 X_i$.  \n",
    "\n",
    "    3. 方差同质性假设: 在任意自变量的取值下，观测值$Y_i$都会以$\\mu_i$为中心，同样的标准差$\\sigma$呈正态分布变化（$\\sigma$ is consistent）.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 当假设1 (独立观测假设) 被违反时：**  \n",
    "\n",
    "* 在心理学的实验数据中，观测值之间常常存在依赖关系 (dependent)。  \n",
    "* 比如，反应时数据在单个被试内、或某种特定刺激类型内可能表现得更加同质：  \n",
    "  * 有的被试（Participant）总是比其他人反应得更快；\n",
    "  * 有的刺激类型（Stimulus）可能总是导致更快的反应。  \n",
    "* 这种观测值的相互关联会导致对结果的不准确估计，具体体现在：\n",
    "  - **过低的标准误**：错误高估了参数的显著性；\n",
    "  - **错误的效应估计**：未能正确捕捉组间差异。  \n",
    "* 解决这种关联问题需要采用层级模型（Hierarchical Models），特别是**层级贝叶斯模型（Hierarchical Bayesian Models）**。这种方法能够同时建模个体差异（如被试间的反应）和组间差异（如刺激类型的影响）。\n",
    "\n",
    "例如，在下图中：\n",
    "* 左图可能低估了被试间的变异性，假设所有被试的反应时间都完全由刺激难度解释。  \n",
    "* 右图通过引入随机截距（Random Intercept）更好地捕捉了被试间的差异，使得模型更贴合数据的实际结构。\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/s3xt2u50rw.png?imageView2/0/w/960/h/960)  \n",
    "1. **左图：单一模型（无随机效应）**  \n",
    "   - 仅考虑整体平均效应，没有控制“被试”或“刺激”的特定差异。  \n",
    "   - 每个数据点的误差条（灰色线条）表示高水平的变异性，线性趋势可能无法很好地反映个体间差异。\n",
    "2. **右图：考虑随机截距模型（Random Intercept Model）**  \n",
    "   - 模型中引入了**被试间的随机截距**（by-participant random intercept），将不同被试的反应时间（RT）的基本差异纳入建模过程。  \n",
    "   - 虚线代表各被试的随机截距，展示了“被试间”的系统性差异；实线代表整体效应估计（包含群体水平的趋势）。  \n",
    "   - 结果更加细化，并能够同时反映群体趋势和个体变异。\n",
    "\n",
    "> source: Brown, V. A. (2021). An Introduction to Linear Mixed-Effects Modeling in R. *Advances in Methods and Practices in Psychological Science, 4*(1), 2515245920960351. https://doi.org/10.1177/2515245920960351\n",
    "\n",
    "<div style=\"padding-bottom: 30px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 当假设2(线性关系假设)和假设3(方差同质性假设)被违反时：**  \n",
    "\n",
    "* 假设2(线性关系假设)违反的情况：在左图中，我们可以看到，Y和X之间的关系并非线性的  \n",
    "\n",
    "* 假设3(方差同质性假设)违反的情况：并且，随着X的增大，Y的变异性越来越大。  \n",
    "\n",
    "  * 这要导致的后果是，后验预测分布比实际观测值的分布差异很大(右图)  \n",
    "\n",
    "![Image Name](https://www.bayesrulesbook.com/bookdown_files/figure-html/nonlinear-1-ch10-1.png)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对模型进行修改  \n",
    "\n",
    "* 考虑到并不是所有数据都会满足这些假设，当这些假设被违反时，我们需要考虑修改模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于违反假设1 的情况，我们在之后会学习使用层级贝叶斯模型来处理相互关联的数据。  \n",
    "\n",
    "**对于违反假设2和3的情况，通常有两种处理方式**  \n",
    "\n",
    "**a. 使用不同的数据模型**  \n",
    "\n",
    "* 不假设实际值与观测值之间的关系是正态的  $Y_i \\sim N(\\mu_i, \\sigma^2)$  \n",
    "\n",
    "* 之后，我们会学习使用其他回归模型来描述其数据关系，比如泊松回归、二项回归、负二项回归。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. 对数据进行变换**  \n",
    "\n",
    "> 如果数据模型并不是我们要担心的问题，我们可以对数据进行变换，仍然可以对变换后的数据可以使用正态模型：  \n",
    "\n",
    "* 对$Y$进行变换：$g(Y_i) | \\beta_0, \\beta_1, \\sigma \\stackrel{ind}{\\sim}N(\\mu_i, \\sigma^2)$，$\\mu_i = \\beta_0 + \\beta_1 X_i$  \n",
    "\n",
    "* 对$X$进行变换： $Y_i | \\beta_0, \\beta_1, \\sigma \\stackrel{ind}{\\sim}N(\\mu_i, \\sigma^2)$，$\\mu_i = \\beta_0 + \\beta_1 h(X_i)$  \n",
    "\n",
    "* 同时对$Y$和$X$进行变换：$g(Y_i) | \\beta_0, \\beta_1, \\sigma \\stackrel{ind}{\\sim}N(\\mu_i, \\sigma^2)$， $\\mu_i = \\beta_0 + \\beta_1 h(X_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在刚刚的例子当中，我们对$Y$的取值做一个对数变换  \n",
    "\n",
    "$$  \n",
    "\\log(Y_i) | \\beta_0, \\beta_1, \\sigma \\stackrel{ind}{\\sim}N(\\mu_i, \\sigma^2) \\;\\; \\text{ with } \\; \\mu_i = \\beta_0 + \\beta_1 X_i  \n",
    "$$  \n",
    "\n",
    "* 在变换之后，可以看到$\\log(Y)$与$X$之间的关系仍然是线性的，且随着$X$的增大，$Y$的变异性仍然是一致的。  \n",
    "\n",
    "* 可以使用正态的线性模型来拟合$\\log(Y)$的后验分布  \n",
    "* 这部分内容将在逻辑回归(logistic regression)部分进行详细介绍，这里先不作深入解释。  \n",
    "\n",
    "<table>  \n",
    "        <tr>  \n",
    "            <td><img src=\"https://www.bayesrulesbook.com/bookdown_files/figure-html/nonlinear-1-ch10-1.png\" alt=\"\" width=\"500\" height=\"250\"></td>  \n",
    "            <td><img src=\"https://www.bayesrulesbook.com/bookdown_files/figure-html/nonlinear-2-ch10-1.png\" alt=\"\" width=\"500\" height=\"250\"></td>  \n",
    "        </tr>  \n",
    "        <tr>  \n",
    "            <td>变换之前</td>  \n",
    "            <td>log变换之后</td>  \n",
    "        </tr>  \n",
    "</table>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评估  \n",
    "\n",
    "一般情况下，我们的贝叶斯模型不会是完全不公平的，或者错得太离谱的。 但除了这些问题，**更为重要的是，模型是否可以用来准确预测新数据 Y 的结果。**  \n",
    "\n",
    "> 如果说模型公平性和模型错误描述的是模型在**质量上**的优劣，那模型评估与比较就是在**数量上**衡量模型预测的准确性。  \n",
    "\n",
    "我们可以通过什么指标来评估预测模型的整体质量呢？\n",
    "\n",
    "- 绝对指标，衡量模型对于样本的预测能力。  \n",
    "- 相对指标，衡量模型对于样本外数据的预测能力，也考虑了模型的复杂度。  \n",
    "\n",
    "首先，我们先向大家介绍可用于评估模型在**样本**数据上的预测能力的绝对指标 ---- 绝对误差的中位数，median absolute error (MAE) \n",
    "- 衡量观测值和其后验预测均之间的典型差异。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 绝对误差的中位数，median absolute error (MAE) \n",
    "\n",
    "**定义**：MAE 是观测值 $(Y_i)$ 和后验预测均值 $( Y_i')$ 的绝对误差的中位数，公式为：\n",
    "$$ \\text{MAE} = \\text{median}(|Y_i - Y_i'|) $$\n",
    "\n",
    "-  $(Y_i)$ ：实际观测值。\n",
    "- $( Y_i')$：模型后验预测的均值。\n",
    "\n",
    "- 假设 $Y_1, Y_2…, Y_n$表示n个观察结果。  \n",
    "\n",
    "- 每个 $Y_i$ 都有对应的后验预测值，其均值为 $Y_i'$  \n",
    "  \n",
    "**作用**：衡量模型预测值和实际观测值之间的典型差异。\n",
    "\n",
    "**特点**：\n",
    "- MAE 是绝对误差的典型值，对异常值的敏感性较低。\n",
    "- 作为绝对指标，直接反映模型的预测精度。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相对指标：样本外预测能力\n",
    "\n",
    "仅在样本数据上评估模型并不足以验证其泛化能力，尤其是心理学数据经常受到时间和抽样偏差的影响。例如：\n",
    "\n",
    "- 比如，个体的压力状态可能随着季节变化，因此在不同季节收集到的数据会受到时间的影响。  \n",
    "- 抽样差异：训练模型的数据可能来自理工科学生，而测试模型的数据来自心理学学生，这种抽样差异可能导致预测性能下降。\n",
    "\n",
    "\n",
    "因此，一种更高效的方法是，一次性多收集一些数据，选择其中的一部分作为预测数据。\n",
    "\n",
    "而**相对指标**更多的是评估模型在**样本外**数据上的，同时考虑模型的复杂度,这更有利于比较不同模型的预测能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交叉验证(cross validation)  \n",
    "\n",
    "但问题在于，我们选择哪一部分数据作为预测数据呐？或者说，我们该如何有效的对数据进行抽取呐？  \n",
    "\n",
    "**交叉验证(cross validation)** 的目的就在于：提供不同的抽取预测数据的策略  \n",
    "- 其关键在于从已有样本中拿出一部分数据当作预测数据。  \n",
    "\n",
    "\n",
    "![](https://pic1.zhimg.com/80/v2-e9ad5ba61cda7ebd02848f336607eb70_1440w.webp)  \n",
    "\n",
    "\n",
    "> 资料来源：【绝对干货】机器学习模型训练全流程！- 知乎 https://zhuanlan.zhihu.com/p/184673895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常见的交叉验证策略：  \n",
    "1. 分半交叉验证 (Split-half cross-validation)  \n",
    "\t- 分半交叉验证将观测数据对半分成两部分，分别在不同的数据集上拟合模型，并在另外一半数据集上验证模型，最后再对比不同的模型在两份数据集作为验证集时的预测准确度。  \n",
    "2. K 折交叉验证 (K-fold cross-validation)  \n",
    "\t- K 折交叉验证把数据分成 K 分，其中一份作为训练集（拟合模型，对参数进行估计），其余的 K-1 分数据集作为验证集，总共重复这个流程 K 次。以 K 次验证结果的均值作为验证标准。  \n",
    "3. 留一法交叉验证 (Leave-one-out cross-validation)  \n",
    "\t- 留一法交叉验证是 K 折交叉验证的一个特例，当分折的数量等于数据的数量时，K 折留一法便成了留一法交叉验证。留一法交叉验证相较于普通的交叉验证方法，几乎使用了所有数据去训练模型，因此留一法交叉验证的训练模型时的**偏差 (bias) 更小、更鲁棒**，但是又因为验证集只有一个数据点，验证模型的时候**留一法交叉验证的方差 (Variance) 也会更大**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K 折交叉验证 (K-fold cross-validation)**  \n",
    "\n",
    "K 折交叉验证在分半交叉验证的基础上，将数据集分成 K 份(称为 CV-K)，其中一份作为测试集，其余 K-1 份作为训练集，重复这个流程 K 次。  \n",
    "\n",
    "K 折交叉验证，以 K 次测试结果的**均值**作为验证标准。例如，在压力-自我控制的例子中：  \n",
    "- 我们可以使用 K=5 折的交叉验证，将数据集分成 5 份，每次使用 4 份数据作为训练集，1份数据作为测试集。  \n",
    "- 对每一次迭代，我们使用 4 份数据训练模型，然后使用剩下的一份数据进行测试，并计算相应的MAE。  \n",
    "- 重复这个流程 5 次，然后取每次MAE测试结果的均值作为最终的测试结果。  \n",
    "\n",
    "![](https://pic3.zhimg.com/80/v2-ff846ee7eefdcd425e123d9d31b4d58a_1440w.webp)  \n",
    "\n",
    "> 资料来源：【绝对干货】机器学习模型训练全流程！- 知乎 https://zhuanlan.zhihu.com/p/184673895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**留一法交叉验证 (Leave-one-out cross-validation)**  \n",
    "\n",
    "留一法交叉验证是 K 折交叉验证的一个特例，当分折的数量K等于数据的数量n时，K 折留一法便成了留一法交叉验证。  \n",
    "- 留一法交叉验证相较于普通的交叉验证方法，几乎使用了所有数据去训练模型。  \n",
    "- 留一法交叉验证 (Leave-one-out cross-validation)的缩写为 loo-cv，或者 loo。  \n",
    "\n",
    "![](https://www.baeldung.com/wp-content/uploads/sites/4/2022/05/loso.png)  \n",
    "\n",
    "> 资料来源：https://www.baeldung.com/cs/cross-validation-k-fold-loo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELPD (Expected log-predictive density)  \n",
    "\n",
    "留一法交叉验证 LOO (包括之前的交叉验证方法)是用于评估模型在**未知数据**上预测能力的思想框架，其本身并不提供具体的统计指标。  \n",
    "\n",
    "**ELPD** (Expected log-predictive density) 是 LOO 方法的具体实现，以对数似然函数作为统计指标。  \n",
    "\n",
    "其计算步骤：  \n",
    "- 同 K 折交叉验证一样，首先将数据集分成 n 份，n为数据总的数量。  \n",
    "- 利用 n-1 份数据去训练模型，得到后验模型 $p(\\theta_{-i}|y_{-i})$。  \n",
    "- 使用剩下的一份数据作为测试数据 $y_{i}$，计算后验预测模型 $p(y_{i}|y_{-i})$。  \n",
    "- 重以上过程，重复 n 次，得到 n 个后验预测模型,并计算其对数化后的期望值 $E(log(p(y_{i}|y_{-i})))$。  \n",
    "\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/s4bmgg7han.png?imageView2/0/w/640/h/640)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 补充：其他指标\n",
    "\n",
    "之前讨论过模型评估中两种类型的指标：  \n",
    "- 绝对指标，衡量模型对于样本的预测能力。  \n",
    "- 相对指标，衡量模型对于样本外数据的预测能力，也考虑了模型的复杂度。  \n",
    "\n",
    "这两种指标包含了多种具体的统计值：  \n",
    "\n",
    "模型拟合优度的方法包括：  \n",
    "- MAE or MSE(mean square error)  \n",
    "- 对数似然 (log likelihood)  \n",
    "- $R^2$  \n",
    "\n",
    "模型预测进度的方法包括：  \n",
    "- AIC  \n",
    "- DIC  \n",
    "- WAIC  \n",
    "- LOO-CV  \n",
    "\n",
    "\n",
    "|                    | AIC                                  | DIC                                      | WAIC       | LOOCV           | BIC                                  |  \n",
    "| ------------------ | ------------------------------------ | ---------------------------------------- | ---------- | --------------- | ------------------------------------ |  \n",
    "| 适用框架           | 频率论                               | 贝叶斯                                   | 贝叶斯     | 贝叶斯          | 贝叶斯/频率论                        |  \n",
    "| 偏差（deviance）   | 最大似然参数 $\\theta_mle$ 的对数似然 | 贝叶斯参数均值 $\\bar{\\theta}$ 的对数似然 | LPPD       | $ELPD_{LOO-CV}$ | 最大似然参数 $\\theta_mle$ 的对数似然 |  \n",
    "| 矫正（correction） | 参数数量                             | 似然的变异                               | 似然的变异 |     由于采用 LOO-CV 思想，因此不需要矫正            | 参数数量+数据数量                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前认知建模在科学心理学中得到了广泛应用，而模型比较作为认知建模的核心环节，不仅是评估模型对数据的拟合优度（平衡过拟合与欠拟合），还需要考虑模型复杂度对预测能力的影响。\n",
    "\n",
    "然而，由于模型比较指标种类繁多，研究者在选用时往往面临困惑。\n",
    "\n",
    "在郭鸣谦等(2024) 的文章中便把常用指标划分为三类，其中AIC、DIC、WAIC 等基于交叉验证的指标，通过数据分割或后验分布计算预测性能，平衡拟合优度和复杂度。\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/snng3h8fir.png?imageView2/0/w/640/h/640)\n",
    "\n",
    "> 郭鸣谦, 潘晚坷, 胡传鹏. (2024). 认知建模中模型比较的方法. *心理科学进展*, *32*(10), 1736-1756. doi: 10.3724/SP.J.1042.2024.01736\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 偏差-方差权衡 (Bias-Variance Trade-off)\n",
    "\n",
    "- 偏差（Bias）：指的是算法的期望预测与真实预测之间的偏差程度， 反应了模型本身的拟合能力。\n",
    "  \n",
    "- 方差（Variance）：用不同训练数据进行模型评估时，模型表现的变化程度。\n",
    "\n",
    "在模型训练过程中，偏差和方差之间存在一定的权衡关系：\n",
    "\n",
    "- 高偏差通常伴随着低方差，即模型较为简单，但能够在不同训练数据集上保持较为稳定的表现；\n",
    "- 低偏差通常伴随着高方差，即模型较为复杂，可以在训练数据上做得很好，但在其他数据集上表现不稳定；\n",
    "- 因此，偏差和方差之间需要达到一种平衡，即偏差-方差权衡，以避免模型过于简单或过于复杂。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "在模型评估中，无论是**绝对评估**还是**相对评估**，都可以结合偏差-方差权衡的概念来理解。偏差-方差权衡揭示了以下关键事实：  \n",
    "\n",
    "- **模型越复杂**：虽然能够更好地拟合训练数据，但往往会失去对样本外数据的解释能力（即过拟合）。  \n",
    "- **模型越简单**：尽管能够在不同样本间保持一致性，但对于任何特定样本的解释力可能较弱（即欠拟合）。  \n",
    "\n",
    "举例说明：\n",
    "- 如果我们的目标是建立一个能够准确预测响应变量 \\( Y \\) 的模型，就需要包含足够多的预测因子，以获得对 \\( Y \\) 的充分信息。  \n",
    "- 然而，加入过多的预测因子可能适得其反。模型不仅会过度拟合训练数据，还可能导致复杂性增加，从而降低泛化能力。\n",
    "\n",
    "通过平衡模型的偏差和方差，我们可以选择一个既能够捕捉数据结构，又具有良好预测能力的模型。这种权衡是建模过程中不可忽视的核心问题。\n",
    "\n",
    "![Image Name](https://vitalflux.com/wp-content/uploads/2020/12/overfitting-and-underfitting-wrt-model-error-vs-complexity-768x443.png)  \n",
    "\n",
    "资料来源：https://vitalflux.com/overfitting-underfitting-concepts-interview-questions/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型评估的核心在于模型捕捉到了数据中的关键模式，既非太简单而错过数据中有价值的信息(**欠拟合, underfitting**)，也不会太复杂从而将数据中的噪音加入到模型中(**过拟合, overfitting**)。  \n",
    "\n",
    "**欠拟合(underfitting)**  \n",
    "\n",
    "* 欠拟合的模型在当前样本的数据拟合效果不好，且其泛化能力(模型在当前样本外新的数据上的预测的准确度)也同样不佳。  \n",
    "* 导致欠拟合的原因  \n",
    "  * 数据特征较少  \n",
    "    * 数据特征指的是数据的属性，比如第一部分中展示的数据的各个变量就是数据的特征。在所有变量都能独立地对目标变量做出解释的前提下，数据特征越多，数据拟合程度越好。  \n",
    "  * 模型复杂度过低  \n",
    "    * 模型的复杂度代表模型能够描述的所有函数，比如线性回归最多能表示所有的线性函数。  \n",
    "    * 模型的复杂度和模型的参数数量有关，一般来说，模型参数越多，复杂度越高，模型参数越少，复杂度越低。  \n",
    "\n",
    "**过拟合(overfitting)**  \n",
    "\n",
    "* 模型在当前样本的数据上的拟合程度极好，但是泛化能力也较差。  \n",
    "* 模型把训练样本学习地“太好了”，把样本自身地一些噪音也当作了所有潜在样本都会具有的一些性质，这样就会导致其泛化性能下降。  \n",
    "* 导致过拟合的原因  \n",
    "  * 当前样本的噪音过大，模型将噪音当作数据本身的特征  \n",
    "  * 当数据的有些特征与目标变量无关，这些特征就是噪音，但它也可能被误当作数据特征，这就会造成模型过拟合  \n",
    "  - 样本选取有误，样本不能代表整体  \n",
    "  - 模型参数太多，模型复杂度太高  \n",
    "\n",
    "\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/s4bp7piw04.png?imageView2/0/w/640/h/640)  \n",
    "\n",
    "\n",
    "资料来源：https://blog.csdn.net/weixin_43378396/article/details/90707493"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何避免欠拟合  \n",
    "\n",
    "- 增加数据的特征  \n",
    "\n",
    "- 增加模型复杂度  \n",
    "\n",
    "### 如何避免过拟合  \n",
    "\n",
    "- 选择更具代表性的数据  \n",
    "\n",
    "- 降低模型复杂度  \n",
    "\n",
    "\n",
    "**问题的本质在于：模型与数据真实的生成模型匹配**  \n",
    "\n",
    "为了选择一个能够在过拟合和欠拟合之间的达到平衡的最佳模型，就需要进行模型评估、比较和选择。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评估指标的代码演示\n",
    "\n",
    "在我们了解模型评估的基本原理和方法后，接下来我们通过代码来演示如何使用这些方法来评估模型。包括：\n",
    "- 绝对指标，MAE\n",
    "- 相对指标，ELPD-LOO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算 MAE\n",
    "\n",
    "MAE 是观测值 $(Y_i)$ 和后验预测均值 $( Y_i')$ 的绝对误差的中位数，公式为：\n",
    "$$ \\text{MAE} = \\text{median}(|Y_i - Y_i'|) $$\n",
    "\n",
    "-  $(Y_i)$ ：实际观测值。\n",
    "- $( Y_i')$：模型后验预测的均值。\n",
    "\n",
    "接下来我们通过代码来演示如何计算 MAE，以 model 1 为例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. 提取后验预测数据，从模型中提取后验预测数据是后续计算的基础。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;Y_obs&#x27; (Y_obs_dim_2: 5)&gt;\n",
       "array([0.70285717, 0.70416979, 0.76634711, 0.76563904, 0.76169855])\n",
       "Coordinates:\n",
       "  * Y_obs_dim_2  (Y_obs_dim_2) int32 0 1 2 3 4</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'Y_obs'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>Y_obs_dim_2</span>: 5</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-a9328ef6-f6a0-481c-956c-be4e1b6be43b' class='xr-array-in' type='checkbox' checked><label for='section-a9328ef6-f6a0-481c-956c-be4e1b6be43b' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>0.7029 0.7042 0.7663 0.7656 0.7617</span></div><div class='xr-array-data'><pre>array([0.70285717, 0.70416979, 0.76634711, 0.76563904, 0.76169855])</pre></div></div></li><li class='xr-section-item'><input id='section-05a149b2-d423-4a7f-acb0-9fb02685de6c' class='xr-section-summary-in' type='checkbox'  checked><label for='section-05a149b2-d423-4a7f-acb0-9fb02685de6c' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>Y_obs_dim_2</span></div><div class='xr-var-dims'>(Y_obs_dim_2)</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>0 1 2 3 4</div><input id='attrs-d6cd1d24-0760-487c-a8f9-a63fc91819d5' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-d6cd1d24-0760-487c-a8f9-a63fc91819d5' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-85acfd36-d695-450b-b906-3c9a838a4707' class='xr-var-data-in' type='checkbox'><label for='data-85acfd36-d695-450b-b906-3c9a838a4707' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0, 1, 2, 3, 4], dtype=int32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-80dc8756-5a43-435a-982c-458ac59897b5' class='xr-section-summary-in' type='checkbox'  ><label for='section-80dc8756-5a43-435a-982c-458ac59897b5' class='xr-section-summary' >Indexes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>Y_obs_dim_2</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-422ee1dd-518b-4bdf-93e9-24685b758eef' class='xr-index-data-in' type='checkbox'/><label for='index-422ee1dd-518b-4bdf-93e9-24685b758eef' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([0, 1, 2, 3, 4], dtype=&#x27;int32&#x27;, name=&#x27;Y_obs_dim_2&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-ce233aab-a209-4b30-a7e2-8473438701e0' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-ce233aab-a209-4b30-a7e2-8473438701e0' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'Y_obs' (Y_obs_dim_2: 5)>\n",
       "array([0.70285717, 0.70416979, 0.76634711, 0.76563904, 0.76169855])\n",
       "Coordinates:\n",
       "  * Y_obs_dim_2  (Y_obs_dim_2) int32 0 1 2 3 4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从采样结果中提取后验预测样本\n",
    "posterior_predictive = model1_trace.posterior_predictive[\"Y_obs\"]\n",
    "\n",
    "# 在draw 和 chain 两个维度上计算后验均值\n",
    "posterior_mean = posterior_predictive.mean(dim=[\"chain\", \"draw\"])\n",
    "\n",
    "posterior_mean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 计算 MAE\n",
    "通过提取的后验预测值，计算 MAE，作为模型预测误差的绝对指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.08791264586944775\n"
     ]
    }
   ],
   "source": [
    "# 计算 MAE（观测值和后验均值的绝对误差的中位数）\n",
    "mae = np.median(np.abs(df[\"RT_sec\"] - posterior_mean))\n",
    "\n",
    "print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于 MAE 的解读。  \n",
    "\n",
    "- 绝对误差的中位数，median absolute error (MAE)衡量了预测观测值$Y_i$与后验预测均值之间$Y_i'$的差异。  \n",
    "- **MAE越小**表明后验模型的**预测越准确**。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以对比三个模型的 MAE 结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mae(trace, observed_data, dv = \"Y_obs\"):\n",
    "    \"\"\"\n",
    "    计算后验预测均值和 MAE (Median Absolute Error)。\n",
    "    \n",
    "    Parameters:\n",
    "    - trace: PyMC 模型的采样结果 (InferenceData 对象)。\n",
    "    - observed_data: 包含真实观测值的 Pandas DataFrame。\n",
    "    - dv: 需要计算 MAE 的数据列名，默认为 \"Y_obs\"。\n",
    "\n",
    "    Returns:\n",
    "    - posterior_mean: 后验预测值的均值。\n",
    "    - mae: 后验预测均值与观测值之间的 MAE。\n",
    "    \"\"\"\n",
    "\n",
    "    # 提取后验预测值\n",
    "    posterior_predictive = trace.posterior_predictive[dv]\n",
    "    \n",
    "    # 计算后验预测均值（在 draw 和 chain 两个维度上取平均值）\n",
    "    posterior_mean = posterior_predictive.mean(dim=[\"chain\", \"draw\"])\n",
    "    \n",
    "    # 计算 MAE（绝对误差的中位数）\n",
    "    mae = np.median(np.abs(observed_data - posterior_mean))\n",
    "    \n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "      <th>Model 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.087913</td>\n",
       "      <td>0.088987</td>\n",
       "      <td>0.089136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model 1   Model 2   Model 3\n",
       "0  0.087913  0.088987  0.089136"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"Model 1\": [calculate_mae(model1_trace, df[\"RT_sec\"], \"Y_obs\")],\n",
    "    \"Model 2\": [calculate_mae(model2_trace, df[\"RT_sec\"], \"Y_obs\")],\n",
    "    \"Model 3\": [calculate_mae(model3_trace, df[\"RT_sec\"], \"Y_obs\")],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算 ELPD-LOO\n",
    "\n",
    "在实际操作中，我们通过 `ArViz` 的函数`az.loo`计算 $ELPD_{LOO-CV}$。  \n",
    "\n",
    "* 在`az.loo`返回的值中，`elpd_loo` 为$E(log(p(y_{i}|y_{-i})))$，  \n",
    "* `elpd_loo`越高表示模型的预测值越精确  \n",
    "\n",
    "注意：由于 $ELPD_{LOO-CV}$ 的计算量也比较大，ArViz 会使用 Pareto Smooth Importance Sampling Leave Once Out Cross Validation (PSIS-LOO-CV) 来近似 $ELPD_{LOO-CV}$。  \n",
    "\n",
    "PSIS-LOO-CV 有两大优势：  \n",
    "1. 计算速度快，且结果稳健  \n",
    "2. 提供了丰富的模型诊断指标  \n",
    "\n",
    "注意：  \n",
    "- 要计算 elpd_loo 需要在采样 `pm.sample` 中加入 `idata_kwargs={\"log_likelihood\": True}`  \n",
    "- 或者，在模型采样完成后计算对数似然，即 `with model:  pm.compute_log_likelihood(model_trace)`。\n",
    "\n",
    "首先，我们以 model 3为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computed from 20000 posterior samples and 186 observations log-likelihood matrix.\n",
       "\n",
       "         Estimate       SE\n",
       "elpd_loo   107.87    10.24\n",
       "p_loo        6.90        -\n",
       "------\n",
       "\n",
       "Pareto k diagnostic values:\n",
       "                         Count   Pct.\n",
       "(-Inf, 0.70]   (good)      186  100.0%\n",
       "   (0.70, 1]   (bad)         0    0.0%\n",
       "   (1, Inf)   (very bad)    0    0.0%"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以 model 3 为例计算elpd_loo\n",
    "\n",
    "az.loo(model3_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型`elpd_loo`的结果为107.87\n",
    "\n",
    "- 然而，仅凭单个值，并不能反映模型的预测精确程度。  \n",
    "- 虽然 **ELPDs 无法为任何单一模型的后验预测准确性提供可解释的度量，但它在比较多个模型的后验预测准确性时非常有用**。  \n",
    "\n",
    "我们可以通过 `arviz.compare` 方法来对比多个模型的 elpd。从下面结果可见：  \n",
    "- 模型1的 elpd_loo 最大，表明它对**样本外数据**的预测性能最好。  \n",
    "- 而模型3的 elpd_loo 最小，表明它的预测性能最差。  \n",
    "- 并且这些结果与我们通过 MAE 计算及上节课的贝叶斯因子计算和HDI+rope 区间计算得到的判断一致。  \n",
    "\n",
    "需要注意的是：  \n",
    "- arviz 提供的结果包括了 elpd se，这使得我们可以判断两个模型的预测差异 elpd_diff 是否超过两至三个标准误se。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>elpd_loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>elpd_diff</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>0</td>\n",
       "      <td>109.551050</td>\n",
       "      <td>4.073800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.388306e-01</td>\n",
       "      <td>10.125275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>1</td>\n",
       "      <td>109.143428</td>\n",
       "      <td>4.994407</td>\n",
       "      <td>0.407622</td>\n",
       "      <td>1.611694e-01</td>\n",
       "      <td>9.949396</td>\n",
       "      <td>1.098084</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model3</th>\n",
       "      <td>2</td>\n",
       "      <td>107.874296</td>\n",
       "      <td>6.901146</td>\n",
       "      <td>1.676754</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>10.235348</td>\n",
       "      <td>1.516092</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank    elpd_loo     p_loo  elpd_diff        weight         se  \\\n",
       "model1     0  109.551050  4.073800   0.000000  8.388306e-01  10.125275   \n",
       "model2     1  109.143428  4.994407   0.407622  1.611694e-01   9.949396   \n",
       "model3     2  107.874296  6.901146   1.676754  1.110223e-16  10.235348   \n",
       "\n",
       "             dse  warning scale  \n",
       "model1  0.000000    False   log  \n",
       "model2  1.098084    False   log  \n",
       "model3  1.516092    False   log  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_list = {\n",
    "    \"model1\":model1_trace,\n",
    "    \"model2\":model2_trace,\n",
    "    \"model3\":model3_trace,\n",
    "}\n",
    "az.compare(comparison_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 补充：DIC在Python中的实现\n",
    "\n",
    "在贝叶斯统计中，DIC 适用于基于 MCMC (Markov chain Monte Carlo) 采样估计的模型。\n",
    "\n",
    "由于PyMc中没有直接计算DIC的方式，我们补充这一内容，方便同学们在练习中参考。\n",
    "\n",
    "\n",
    "**DIC 的计算公式为：**\n",
    "\n",
    "$$\n",
    "\\text{DIC} = -2D(\\bar{\\theta}) + 2 \\times p_D\n",
    "$$\n",
    "\n",
    "- 其中，$\\bar{\\theta}$ 为参数后验分布的均值，而 $D(\\theta)$ 则是真实数据与模型预测分布之间的偏差（Deviance），用以衡量模型的性能；\n",
    "\n",
    "- DIC 公式的第一项是 $-2$ 乘上参数后验分布上的均值的偏差，代表了模型拟合的程度；\n",
    "\n",
    "- 第二项 $p_D$ 被称作有效参数（effective number of parameters），是模型拟合的复杂度的惩罚项。\n",
    "\n",
    "DIC 综合考虑了模型的拟合优度和复杂度。模型的 DIC 值越低，说明模型在平衡拟合优度与复杂度后表现越好。\n",
    "\n",
    "DIC（Deviance Information Criterion）是用于模型选择和评估的指标，通常用于贝叶斯模型。在统计学中，DIC 是一种衡量模型拟合优度和复杂度的指标，类似于AIC（Akaike Information Criterion）和BIC（Bayesian Information Criterion）。\n",
    "\n",
    "**偏差的公式为：**\n",
    "\n",
    "$$\n",
    "D(\\theta_s) = \\log L(y|\\theta_s) \\tag{15}\n",
    "$$\n",
    "\n",
    "其中 $s$ 代表了 MCMC 的样本，因此 $\\theta_s$ 是 MCMC 样本的参数值。\n",
    "\n",
    "**有效参数 $p_D$**\n",
    "\n",
    "$p_D$ 为有效参数(effective number of parameters), 是模型拟合的复杂度的惩罚项, 计算公式如下：\n",
    "$$\n",
    "p_D = \\text{Var}(D(\\theta)) = \\frac{1}{M} \\sum_{m=1}^{M} D(\\theta^{(m)}) - D(\\hat{\\theta})\n",
    "$$\n",
    "- 其中，$D(\\theta^{(m)})$ 是第 $m$ 个样本的偏差，$\\hat{\\theta}$ 是后验均值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**代码实现：**\n",
    "\n",
    "要根据模型的 **log-likelihood** 结果计算 DIC (Deviance Information Criterion)，可以按照以下步骤操作：\n",
    "\n",
    "假设 `model_trace.log_likelihood[\"Y_obs\"]` 是后验采样的 log-likelihood 值。\n",
    "\n",
    "**log-likelihood 的结构**：\n",
    "- `log_likelihood` 是一个包含多个链和采样的对数似然值矩阵。\n",
    "- 在 `chain` 和 `draw` 维度上计算均值可以得到每个观测值的平均 log-likelihood。\n",
    "\n",
    "首先，我们以model1为例进行演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dic(log_likelihood):\n",
    "    \"\"\"\n",
    "    根据 log-likelihood 计算 DIC (Deviance Information Criterion)。 参考 Evans, N. J. (2019). Assessing the practical differences between model selection methods in inferences about choice response time tasks. Psychonomic Bulletin & Review, 26(4), 1070–1098. https://doi.org/10.3758/s13423-018-01563-9\n",
    "    \n",
    "    Parameters:\n",
    "    - log_likelihood: xarray 数据集，包含每个链和样本的 log-likelihood 值。\n",
    "    \n",
    "    Returns:\n",
    "    - dic: 计算得到的 DIC 值。\n",
    "    \"\"\"\n",
    "    # 计算每个样本的Deviance\n",
    "    deviance_samples = -2 * log_likelihood\n",
    "    \n",
    "    # 计算平均Deviance\n",
    "    D_bar = deviance_samples.mean()\n",
    "    \n",
    "    # 计算有效自由度 p_D\n",
    "    p_D = deviance_samples.max() - D_bar\n",
    "    \n",
    "    # 计算DIC\n",
    "    DIC = -2 * (D_bar - p_D)\n",
    "    \n",
    "    return DIC[\"Y_obs\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIC 值: 28.29209986121615\n"
     ]
    }
   ],
   "source": [
    "# 调用 compute_dic 函数\n",
    "dic_value = calculate_dic(model1_trace.log_likelihood)\n",
    "print(f\"DIC 值: {dic_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样我们可以计算所有模型（model1，model2，model3）的 DIC 值进行对比："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "      <th>Model 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.29209986121615</td>\n",
       "      <td>24.679373842803408</td>\n",
       "      <td>27.387719057819087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model 1             Model 2             Model 3\n",
       "0  28.29209986121615  24.679373842803408  27.387719057819087"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"Model 1\": [calculate_dic(model1_trace.log_likelihood)],\n",
    "    \"Model 2\": [calculate_dic(model2_trace.log_likelihood)],\n",
    "    \"Model 3\": [calculate_dic(model3_trace.log_likelihood)],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🤔思考：  \n",
    "\n",
    "1. 如果你的目标是在不控制任何其他因素的情况下探索反应时间和什么有关，你会使用哪种模型？  \n",
    "    \n",
    "    - 考虑到模型1优于模型2和模型3--因此，选择模型1可能能更好地反应反应时间的变化。 \n",
    "        \n",
    "2. 如果你的目标是最大限度地提高模型的预测能力，而在模型中只能选择一个预测因子，您会选择Label还是Matching？  \n",
    "    \n",
    "    - 由于模型1优于模型2，如果仅选择一个预测变量的话，选择Label能获得对于反应时间更好的预测。  \n",
    "        \n",
    "3. 这四个模型中，哪个模型的**总体预测结果**最好？  \n",
    "    - 模型1以微弱优势超过了使用所有预测因子的模型2。这表明，在建立模型的过程中，预测因子并不是越多越好。  \n",
    "    - 事实上，模型3比模型2还差一点，这表明Label和matching之间的交互效应很弱，加入两者的交互项，会减弱模型的预测能力。  \n",
    " \n",
    " 因此，为了简单高效，我们更有理由选择模型1。  \n",
    " \n",
    " ![](https://th.bing.com/th/id/R.31c49d0bc73e477eda2cf52fef1b859f?rik=fdM9GvPWnNMg4Q&riu=http%3a%2f%2fwww.esafety.cn%2fblog%2fUploadFiles%2f2018-7%2f51155444445.jpg&ehk=O2MXHgnsmdvS68QMhw6CaIw82aHg2E0q%2fSKKtutAZjk%3d&risl=&pid=ImgRaw&r=0)  \n",
    " \n",
    " > 资料来源: http://www.esafety.cn/Blog/u/9490/archives/2018/154367.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EC1B486952E4686BC1AFB4478680E70",
    "jupyter": {},
    "notebookId": "655b69f19f41eb29b96aa410",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 练习: 当自变量为连续变量\n",
    "\n",
    "### 模型回顾  \n",
    "\n",
    "在第十课的练习部分，我们探究了自我控制水平是否压力和吸烟有关，分别建立了三个回归模型，本节课的练习将基于上节课建立的三个模型进行。\n",
    "\n",
    "💡 如果上节课的练习没有完成，是无法完成本节课的练习的哦！（难度 🔝🔝🔝）\n",
    "\n",
    "\n",
    "<table>  \n",
    "    <tr>  \n",
    "        <td>模型</td>  \n",
    "        <td>model1</td>  \n",
    "        <td>model2</td> \n",
    "        <td>model3</td>  \n",
    "    </tr>  \n",
    "    <tr>  \n",
    "        <td>自变量</td>  \n",
    "        <td>压力(连续变量)</td>  \n",
    "        <td>压力(连续变量)，吸烟(离散变量)【无交互】</td> \n",
    "        <td>压力(连续变量)，吸烟(离散变量)【有交互】</td>   \n",
    "    </tr>  \n",
    "    <tr>  \n",
    "        <td>自变量含义</td>  \n",
    "        <td colspan=\"3\">压力（14-70的压力评级）；吸烟（`0` 表示不吸烟，`1` 表示吸烟）</td>  \n",
    "    </tr>  \n",
    "    <tr>  \n",
    "        <td>先验</td>  \n",
    "        <td>  \n",
    "            β0 ~ N(50, 10) <br>  \n",
    "            β1 ~ N(0, 10) <br>  \n",
    "            σ ~ Exp(0.6) <br>  \n",
    "        </td>  \n",
    "        <td>  \n",
    "            β0 ~ N(50, 10) <br>  \n",
    "            β1 ~ N(0, 10) <br> \n",
    "            β2 ~ N(0, 10) <br>   \n",
    "            σ ~ Exp(0.6) <br>  \n",
    "        </td> \n",
    "        <td>  \n",
    "            β0 ~ N(50, 10) <br>  \n",
    "            β1 ~ N(0, 10) <br> \n",
    "            β2 ~ N(0, 10) <br>  \n",
    "            β3 ~ N(0, 10) <br>  \n",
    "            σ ~ Exp(0.6) <br>  \n",
    "        </td>  \n",
    "    </tr>  \n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 pymc 模型包，和 arviz 等分析工具 \n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 忽略不必要的警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过 pd.read_csv 加载数据 Data_Sum_HPP_Multi_Site_Share.csv\n",
    "try:\n",
    "  df_re = pd.read_csv('/home/mw/input/bayes3797/Data_Sum_HPP_Multi_Site_Share.csv')\n",
    "except:\n",
    "  df_re = pd.read_csv('data/Data_Sum_HPP_Multi_Site_Share.csv')\n",
    "\n",
    "\n",
    "# 筛选站点为\"Tsinghua\"的数据\n",
    "df = df_re[df_re[\"Site\"] == \"Tsinghua\"]\n",
    "\n",
    "df = df[[\"stress\",\"scontrol\",\"smoke\"]]\n",
    "\n",
    "#1 表示吸烟，2表示不吸烟\n",
    "df[\"smoke\"] =  np.where(df['smoke'] == 2, 0, 1)\n",
    "df[\"smoke_recode\"] =  np.where(df['smoke'] == 1, \"yes\", \"no\")\n",
    "\n",
    "\n",
    "#设置索引\n",
    "df[\"index\"] = range(len(df))\n",
    "df = df.set_index(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-------------------------------------------------\n",
    "#     定义模型4、5、6，补全...部分\n",
    "#---------------------------------------------------\n",
    "\n",
    "\n",
    "with pm.Model() as model4:\n",
    "\n",
    "    beta_0 = pm.Normal(\"beta_0\", mu=..., sigma=...)            \n",
    "    beta_1 = pm.Normal(\"beta_1\", mu=..., sigma=...)        \n",
    "    sigma = pm.Exponential(\"sigma\", ...)               \n",
    "\n",
    "    x = pm.MutableData(\"smoke\",df.stress)                   \n",
    "    mu = pm.Deterministic(\"mu\", beta_0 + beta_1*x)          \n",
    "\n",
    "    likelihood = pm.Normal(\"y_est\", mu=mu, sigma=sigma, observed=df.scontrol)\n",
    "\n",
    "\n",
    "with pm.Model() as model5:\n",
    "\n",
    "    beta_0 = pm.Normal(\"beta_0\", mu=..., sigma=...)                \n",
    "    beta_1 = pm.Normal(\"beta_1\", mu=..., sigma=...)          \n",
    "    beta_2 = pm.Normal(\"beta_2\", mu=..., sigma=...)           \n",
    "    sigma = pm.Exponential(\"sigma\", ...)                   \n",
    "\n",
    "    stress = pm.MutableData(\"stress\",df.stress)                          \n",
    "    smoke = pm.MutableData(\"smoke\",df.smoke)                              \n",
    "    mu = pm.Deterministic(\"mu\", beta_0 + beta_1*stress + beta_2*smoke)    \n",
    "\n",
    "    likelihood = pm.Normal(\"y_est\", mu=mu, sigma=sigma, observed=df.scontrol) \n",
    "\n",
    "with pm.Model() as model6:\n",
    "    beta_0 = pm.Normal(\"beta_0\", mu=..., sigma=...)        \n",
    "    beta_1 = pm.Normal(\"beta_1\", mu=..., sigma=...)        \n",
    "    beta_2 = pm.Normal(\"beta_2\", mu=..., sigma=...)        \n",
    "    beta_3 = pm.Normal(\"beta_3\", mu=..., sigma=...)          \n",
    "    sigma = pm.Exponential(\"sigma\", ...)                 \n",
    "\n",
    "    stress = pm.MutableData(\"stress\",df.stress)      \n",
    "    smoke = pm.MutableData(\"smoke\",df.smoke)         \n",
    "    mu = pm.Deterministic(\"mu\", beta_0 + \n",
    "                                beta_1*stress + \n",
    "                                beta_2*smoke +\n",
    "                                beta_3*stress*smoke)      \n",
    "\n",
    "    likelihood = pm.Normal(\"y_est\", mu=mu, sigma=sigma, observed=df.scontrol) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================\n",
    "#     注意！！！以下代码可能需要运行 5 分钟左右,直接运行即可\n",
    "#     直接运行即可，无需修改\n",
    "#========================================\n",
    "\n",
    "def run_model_sampling(save_name, model=None, draws=2000, tune=1000, chains=4, random_seed=84735):\n",
    "    \"\"\"\n",
    "    运行模型采样，并在结果不存在时进行采样，存在时直接加载结果。\n",
    "\n",
    "    Parameters:\n",
    "    - save_name: 用于保存或加载结果的文件名（无扩展名）\n",
    "    - model: pymc 模型\n",
    "    - draws: 采样次数 (默认5000)\n",
    "    - tune: 调整采样策略的次数 (默认1000)\n",
    "    - chains: 链数 (默认4)\n",
    "    - random_seed: 随机种子 (默认84735)\n",
    "\n",
    "    Returns:\n",
    "    - trace: 采样结果\n",
    "    \"\"\"\n",
    "    \n",
    "    # 检查是否存在保存的.nc文件\n",
    "    nc_file = f\"{save_name}.nc\"\n",
    "    if os.path.exists(nc_file):\n",
    "        print(f\"加载现有的采样结果：{nc_file}\")\n",
    "        # 如果文件存在，则加载采样结果\n",
    "        trace = az.from_netcdf(nc_file)\n",
    "    else:\n",
    "\n",
    "        assert model is not None, \"模型未定义，请先定义模型\"\n",
    "\n",
    "        print(f\"没有找到现有的采样结果，正在执行采样：{save_name}\")\n",
    "        # 如果文件不存在，则进行采样计算\n",
    "        with model:\n",
    "            trace = pm.sample_prior_predictive(draws=draws, random_seed=random_seed)\n",
    "            idata = pm.sample(draws=draws,                   # 使用mcmc方法进行采样，draws为采样次数\n",
    "                              tune=tune,                    # tune为调整采样策略的次数\n",
    "                              chains=chains,                # 链数\n",
    "                              discard_tuned_samples=True,   # tune的结果将在采样结束后被丢弃\n",
    "                              idata_kwargs={\"log_likelihood\": True},\n",
    "                              random_seed=random_seed)      # 后验采样\n",
    "\n",
    "            trace.extend(idata)\n",
    "            # 进行后验预测并扩展推断数据\n",
    "            pm.sample_posterior_predictive(trace, extend_inferencedata=True, random_seed=random_seed)\n",
    "            \n",
    "            # 保存结果到指定文件\n",
    "        trace.to_netcdf(nc_file)\n",
    "        \n",
    "    return trace\n",
    "\n",
    "\n",
    "# 运行所有三个模型\n",
    "model4_trace = run_model_sampling(\"lec10_model4\",model4)\n",
    "model5_trace = run_model_sampling(\"lec10_model5\",model5)\n",
    "model6_trace = run_model_sampling(\"lec10_model6\",model6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接运行即可，无需修改\n",
    "# 将3个模型中的inference data 中的 y_est 统一改为 Y_obs\n",
    "\n",
    "model4_trace = model4_trace.rename({\"y_est\": \"Y_obs\"})\n",
    "model5_trace = model5_trace.rename({\"y_est\": \"Y_obs\"})\n",
    "model6_trace = model6_trace.rename({\"y_est\": \"Y_obs\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "341D8D963EF94F83909D7D290FEF029D",
    "jupyter": {},
    "notebookId": "655b69f19f41eb29b96aa410",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 计算MAE：  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接运行即可，无需修改\n",
    "def calculate_mae(trace, observed_data, dv = \"Y_obs\"):\n",
    "    \"\"\"\n",
    "    计算后验预测均值和 MAE (Median Absolute Error)。\n",
    "    \n",
    "    Parameters:\n",
    "    - trace: PyMC 模型的采样结果 (InferenceData 对象)。\n",
    "    - observed_data: 包含真实观测值的 Pandas DataFrame。\n",
    "    - dv: 需要计算 MAE 的数据列名，默认为 \"Y_obs\"。\n",
    "\n",
    "    Returns:\n",
    "    - posterior_mean: 后验预测值的均值。\n",
    "    - mae: 后验预测均值与观测值之间的 MAE。\n",
    "    \"\"\"\n",
    "\n",
    "    # 提取后验预测值\n",
    "    posterior_predictive = trace.posterior_predictive[dv]\n",
    "    \n",
    "    # 计算后验预测均值（在 draw 和 chain 两个维度上取平均值）\n",
    "    posterior_mean = posterior_predictive.mean(dim=[\"chain\", \"draw\"])\n",
    "    \n",
    "    # 计算 MAE（绝对误差的中位数）\n",
    "    mae = np.median(np.abs(observed_data - posterior_mean))\n",
    "    \n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "02DDF112F5DB4B7DA9F900D12A9D1A92",
    "jupyter": {},
    "notebookId": "655b69f19f41eb29b96aa410",
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 4</th>\n",
       "      <th>Model 5</th>\n",
       "      <th>Model 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.417442</td>\n",
       "      <td>3.525749</td>\n",
       "      <td>3.548162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model 4   Model 5   Model 6\n",
       "0  3.417442  3.525749  3.548162"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##================================================\n",
    "#                练习，修改... 部分\n",
    "#                \n",
    "#================================================\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Model 4\": [calculate_mae(model4_trace, df[\"...\"], \"...\")],\n",
    "    \"Model 5\": [calculate_mae(model5_trace, df[\"...\"], \"...\")],\n",
    "    \"Model 6\": [calculate_mae(model6_trace, df[\"...\"], \"...\")],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D8BB6EF497C4F19B5DAAAE57E3E18E9",
    "jupyter": {},
    "notebookId": "655b69f19f41eb29b96aa410",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 计算elpd_loo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##================================================\n",
    "#                练习，修改... 部分       \n",
    "#================================================\n",
    "\n",
    "comparison_list = {\n",
    "    \"model4(contiunous)\":...,\n",
    "    \"model5(multivariate )\":...,\n",
    "    \"model6(interaction)\":...,\n",
    "}\n",
    "az.compare(comparison_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算DIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接运行即可，无需修改\n",
    "def calculate_dic(log_likelihood):\n",
    "    \"\"\"\n",
    "    根据 log-likelihood 计算 DIC (Deviance Information Criterion)。 参考 Evans, N. J. (2019). Assessing the practical differences between model selection methods in inferences about choice response time tasks. Psychonomic Bulletin & Review, 26(4), 1070–1098. https://doi.org/10.3758/s13423-018-01563-9\n",
    "    \n",
    "    Parameters:\n",
    "    - log_likelihood: xarray 数据集，包含每个链和样本的 log-likelihood 值。\n",
    "    \n",
    "    Returns:\n",
    "    - dic: 计算得到的 DIC 值。\n",
    "    \"\"\"\n",
    "    # 计算每个样本的Deviance\n",
    "    deviance_samples = -2 * log_likelihood\n",
    "    \n",
    "    # 计算平均Deviance\n",
    "    D_bar = deviance_samples.mean()\n",
    "    \n",
    "    # 计算有效自由度 p_D\n",
    "    p_D = deviance_samples.max() - D_bar\n",
    "    \n",
    "    # 计算DIC\n",
    "    DIC = -2 * (D_bar - p_D)\n",
    "    \n",
    "    return DIC[\"Y_obs\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##================================================\n",
    "#                练习，修改... 部分\n",
    "#                \n",
    "#================================================\n",
    "\n",
    "DIC_list = {\n",
    "    \"m4_dic_value\":calculate_dic(...),\n",
    "    \"m5_dic_value\":calculate_dic(...),\n",
    "    \"m6_dic_value\":calculate_dic(...),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "176D85859A004A0A9B12516FB09957F3",
    "jupyter": {},
    "notebookId": "655b69f19f41eb29b96aa410",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 总结  \n",
    "\n",
    "本节课从不同模型评估的角度，介绍了模型评估与比较的基本思想。\n",
    "\n",
    "通过学习，我们对贝叶斯分析的整体流程（Bayesian workflow）有了初步的理解。\n",
    "\n",
    "在接下来的课程中，我们将不断实践这一流程，帮助大家更深入地领略贝叶斯分析的独特魅力。\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/rkz1ehen1l.png?imageView2/0/w/960/h/960)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc5_3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
